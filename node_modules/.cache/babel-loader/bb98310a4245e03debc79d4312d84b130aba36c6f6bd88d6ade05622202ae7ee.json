{"ast":null,"code":"import { SYSTEM_PROMPT } from '../config/storyConfig';\n\n// 응답 캐시\nconst cache = new Map();\nconst MAX_CACHE_SIZE = 20;\nfunction generateCacheKey(context, userMessage) {\n  return `${context.affectionScore}_${context.turnCount}_${userMessage.substring(0, 50)}`;\n}\nexport async function generateAIResponse(apiKey, userMessage, context, retryCount = 0) {\n  const {\n    storyConfig,\n    affectionScore,\n    excitementLevel,\n    turnCount,\n    conversationHistory\n  } = context;\n\n  // 캐시 확인\n  const cacheKey = generateCacheKey(context, userMessage);\n  if (cache.has(cacheKey)) {\n    console.log('✅ 캐시 사용');\n    return cache.get(cacheKey);\n  }\n\n  // 대화 히스토리 (최근 3턴)\n  const recentHistory = conversationHistory.slice(-3);\n  const historyText = recentHistory.map(h => `사용자: ${h.user}\\nAI: ${h.ai}`).join('\\n\\n');\n  const prompt = `\n캐릭터 설정:\n공: ${storyConfig.characterA.name} (${storyConfig.characterA.age}세) - ${storyConfig.characterA.personality}\n수: ${storyConfig.characterB.name} (${storyConfig.characterB.age}세) - ${storyConfig.characterB.personality}\n관계: ${storyConfig.scenario.relationship}\n장소: ${storyConfig.scenario.location}\n\n현재 상태:\n- 호감도: ${affectionScore}/100\n- 흥분도: ${excitementLevel}%\n- 턴: ${turnCount}\n\n${historyText ? '최근 대화:\\n' + historyText + '\\n\\n' : ''}\n\n사용자 행동: ${userMessage}\n\n${SYSTEM_PROMPT}`;\n  try {\n    var _data$candidates;\n    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${apiKey}`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        contents: [{\n          parts: [{\n            text: prompt\n          }]\n        }]\n      })\n    });\n\n    // 과부하 시 재시도\n    if (response.status === 503 || response.status === 429) {\n      if (retryCount < 3) {\n        const waitTime = (retryCount + 1) * 3000;\n        console.log(`⏳ ${waitTime / 1000}초 후 재시도... (${retryCount + 1}/3)`);\n        await new Promise(resolve => setTimeout(resolve, waitTime));\n        return generateAIResponse(apiKey, userMessage, context, retryCount + 1);\n      }\n      throw new Error('서버가 과부하 상태입니다. 잠시 후 다시 시도해주세요.');\n    }\n    if (!response.ok) {\n      var _errorData$error;\n      const errorData = await response.json().catch(() => ({}));\n      throw new Error(((_errorData$error = errorData.error) === null || _errorData$error === void 0 ? void 0 : _errorData$error.message) || `HTTP ${response.status}`);\n    }\n    const data = await response.json();\n    if (!((_data$candidates = data.candidates) !== null && _data$candidates !== void 0 && _data$candidates[0])) {\n      throw new Error('AI 응답이 비어있습니다.');\n    }\n    let text = data.candidates[0].content.parts[0].text;\n    let result;\n    try {\n      // JSON 파싱\n      text = text.replace(/```json\\n?/g, '').replace(/```\\n?/g, '');\n      const jsonMatch = text.match(/\\{[\\s\\S]*\\}/);\n      result = jsonMatch ? JSON.parse(jsonMatch[0]) : {\n        narration: text.substring(0, 300),\n        dialogues: [],\n        affection_change: 0,\n        excitement_change: 0,\n        choices: [\"계속하기\"]\n      };\n    } catch (e) {\n      console.error('JSON 파싱 실패:', e);\n      result = {\n        narration: text.substring(0, 300),\n        dialogues: [],\n        affection_change: 0,\n        excitement_change: 0,\n        choices: [\"계속하기\"]\n      };\n    }\n\n    // 캐시 저장\n    if (cache.size >= MAX_CACHE_SIZE) {\n      const firstKey = cache.keys().next().value;\n      cache.delete(firstKey);\n    }\n    cache.set(cacheKey, result);\n    return result;\n  } catch (error) {\n    console.error('AI 서비스 오류:', error);\n    throw error;\n  }\n}","map":{"version":3,"names":["SYSTEM_PROMPT","cache","Map","MAX_CACHE_SIZE","generateCacheKey","context","userMessage","affectionScore","turnCount","substring","generateAIResponse","apiKey","retryCount","storyConfig","excitementLevel","conversationHistory","cacheKey","has","console","log","get","recentHistory","slice","historyText","map","h","user","ai","join","prompt","characterA","name","age","personality","characterB","scenario","relationship","location","_data$candidates","response","fetch","method","headers","body","JSON","stringify","contents","parts","text","status","waitTime","Promise","resolve","setTimeout","Error","ok","_errorData$error","errorData","json","catch","error","message","data","candidates","content","result","replace","jsonMatch","match","parse","narration","dialogues","affection_change","excitement_change","choices","e","size","firstKey","keys","next","value","delete","set"],"sources":["/Users/a1/kind-cat-complete/src/utils/aiService.js"],"sourcesContent":["import { SYSTEM_PROMPT } from '../config/storyConfig';\n\n// 응답 캐시\nconst cache = new Map();\nconst MAX_CACHE_SIZE = 20;\n\nfunction generateCacheKey(context, userMessage) {\n  return `${context.affectionScore}_${context.turnCount}_${userMessage.substring(0, 50)}`;\n}\n\nexport async function generateAIResponse(apiKey, userMessage, context, retryCount = 0) {\n  const { storyConfig, affectionScore, excitementLevel, turnCount, conversationHistory } = context;\n  \n  // 캐시 확인\n  const cacheKey = generateCacheKey(context, userMessage);\n  if (cache.has(cacheKey)) {\n    console.log('✅ 캐시 사용');\n    return cache.get(cacheKey);\n  }\n\n  // 대화 히스토리 (최근 3턴)\n  const recentHistory = conversationHistory.slice(-3);\n  const historyText = recentHistory.map(h => \n    `사용자: ${h.user}\\nAI: ${h.ai}`\n  ).join('\\n\\n');\n\n  const prompt = `\n캐릭터 설정:\n공: ${storyConfig.characterA.name} (${storyConfig.characterA.age}세) - ${storyConfig.characterA.personality}\n수: ${storyConfig.characterB.name} (${storyConfig.characterB.age}세) - ${storyConfig.characterB.personality}\n관계: ${storyConfig.scenario.relationship}\n장소: ${storyConfig.scenario.location}\n\n현재 상태:\n- 호감도: ${affectionScore}/100\n- 흥분도: ${excitementLevel}%\n- 턴: ${turnCount}\n\n${historyText ? '최근 대화:\\n' + historyText + '\\n\\n' : ''}\n\n사용자 행동: ${userMessage}\n\n${SYSTEM_PROMPT}`;\n\n  try {\n    const response = await fetch(\n      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${apiKey}`,\n      {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          contents: [{ parts: [{ text: prompt }] }]\n        })\n      }\n    );\n\n    // 과부하 시 재시도\n    if (response.status === 503 || response.status === 429) {\n      if (retryCount < 3) {\n        const waitTime = (retryCount + 1) * 3000;\n        console.log(`⏳ ${waitTime/1000}초 후 재시도... (${retryCount + 1}/3)`);\n        await new Promise(resolve => setTimeout(resolve, waitTime));\n        return generateAIResponse(apiKey, userMessage, context, retryCount + 1);\n      }\n      throw new Error('서버가 과부하 상태입니다. 잠시 후 다시 시도해주세요.');\n    }\n\n    if (!response.ok) {\n      const errorData = await response.json().catch(() => ({}));\n      throw new Error(errorData.error?.message || `HTTP ${response.status}`);\n    }\n\n    const data = await response.json();\n    \n    if (!data.candidates?.[0]) {\n      throw new Error('AI 응답이 비어있습니다.');\n    }\n\n    let text = data.candidates[0].content.parts[0].text;\n    let result;\n\n    try {\n      // JSON 파싱\n      text = text.replace(/```json\\n?/g, '').replace(/```\\n?/g, '');\n      const jsonMatch = text.match(/\\{[\\s\\S]*\\}/);\n      \n      result = jsonMatch ? JSON.parse(jsonMatch[0]) : {\n        narration: text.substring(0, 300),\n        dialogues: [],\n        affection_change: 0,\n        excitement_change: 0,\n        choices: [\"계속하기\"]\n      };\n    } catch (e) {\n      console.error('JSON 파싱 실패:', e);\n      result = {\n        narration: text.substring(0, 300),\n        dialogues: [],\n        affection_change: 0,\n        excitement_change: 0,\n        choices: [\"계속하기\"]\n      };\n    }\n\n    // 캐시 저장\n    if (cache.size >= MAX_CACHE_SIZE) {\n      const firstKey = cache.keys().next().value;\n      cache.delete(firstKey);\n    }\n    cache.set(cacheKey, result);\n\n    return result;\n\n  } catch (error) {\n    console.error('AI 서비스 오류:', error);\n    throw error;\n  }\n}\n"],"mappings":"AAAA,SAASA,aAAa,QAAQ,uBAAuB;;AAErD;AACA,MAAMC,KAAK,GAAG,IAAIC,GAAG,CAAC,CAAC;AACvB,MAAMC,cAAc,GAAG,EAAE;AAEzB,SAASC,gBAAgBA,CAACC,OAAO,EAAEC,WAAW,EAAE;EAC9C,OAAO,GAAGD,OAAO,CAACE,cAAc,IAAIF,OAAO,CAACG,SAAS,IAAIF,WAAW,CAACG,SAAS,CAAC,CAAC,EAAE,EAAE,CAAC,EAAE;AACzF;AAEA,OAAO,eAAeC,kBAAkBA,CAACC,MAAM,EAAEL,WAAW,EAAED,OAAO,EAAEO,UAAU,GAAG,CAAC,EAAE;EACrF,MAAM;IAAEC,WAAW;IAAEN,cAAc;IAAEO,eAAe;IAAEN,SAAS;IAAEO;EAAoB,CAAC,GAAGV,OAAO;;EAEhG;EACA,MAAMW,QAAQ,GAAGZ,gBAAgB,CAACC,OAAO,EAAEC,WAAW,CAAC;EACvD,IAAIL,KAAK,CAACgB,GAAG,CAACD,QAAQ,CAAC,EAAE;IACvBE,OAAO,CAACC,GAAG,CAAC,SAAS,CAAC;IACtB,OAAOlB,KAAK,CAACmB,GAAG,CAACJ,QAAQ,CAAC;EAC5B;;EAEA;EACA,MAAMK,aAAa,GAAGN,mBAAmB,CAACO,KAAK,CAAC,CAAC,CAAC,CAAC;EACnD,MAAMC,WAAW,GAAGF,aAAa,CAACG,GAAG,CAACC,CAAC,IACrC,QAAQA,CAAC,CAACC,IAAI,SAASD,CAAC,CAACE,EAAE,EAC7B,CAAC,CAACC,IAAI,CAAC,MAAM,CAAC;EAEd,MAAMC,MAAM,GAAG;AACjB;AACA,KAAKhB,WAAW,CAACiB,UAAU,CAACC,IAAI,KAAKlB,WAAW,CAACiB,UAAU,CAACE,GAAG,QAAQnB,WAAW,CAACiB,UAAU,CAACG,WAAW;AACzG,KAAKpB,WAAW,CAACqB,UAAU,CAACH,IAAI,KAAKlB,WAAW,CAACqB,UAAU,CAACF,GAAG,QAAQnB,WAAW,CAACqB,UAAU,CAACD,WAAW;AACzG,MAAMpB,WAAW,CAACsB,QAAQ,CAACC,YAAY;AACvC,MAAMvB,WAAW,CAACsB,QAAQ,CAACE,QAAQ;AACnC;AACA;AACA,SAAS9B,cAAc;AACvB,SAASO,eAAe;AACxB,OAAON,SAAS;AAChB;AACA,EAAEe,WAAW,GAAG,UAAU,GAAGA,WAAW,GAAG,MAAM,GAAG,EAAE;AACtD;AACA,UAAUjB,WAAW;AACrB;AACA,EAAEN,aAAa,EAAE;EAEf,IAAI;IAAA,IAAAsC,gBAAA;IACF,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAC1B,gGAAgG7B,MAAM,EAAE,EACxG;MACE8B,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QAAE,cAAc,EAAE;MAAmB,CAAC;MAC/CC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnBC,QAAQ,EAAE,CAAC;UAAEC,KAAK,EAAE,CAAC;YAAEC,IAAI,EAAEnB;UAAO,CAAC;QAAE,CAAC;MAC1C,CAAC;IACH,CACF,CAAC;;IAED;IACA,IAAIU,QAAQ,CAACU,MAAM,KAAK,GAAG,IAAIV,QAAQ,CAACU,MAAM,KAAK,GAAG,EAAE;MACtD,IAAIrC,UAAU,GAAG,CAAC,EAAE;QAClB,MAAMsC,QAAQ,GAAG,CAACtC,UAAU,GAAG,CAAC,IAAI,IAAI;QACxCM,OAAO,CAACC,GAAG,CAAC,KAAK+B,QAAQ,GAAC,IAAI,eAAetC,UAAU,GAAG,CAAC,KAAK,CAAC;QACjE,MAAM,IAAIuC,OAAO,CAACC,OAAO,IAAIC,UAAU,CAACD,OAAO,EAAEF,QAAQ,CAAC,CAAC;QAC3D,OAAOxC,kBAAkB,CAACC,MAAM,EAAEL,WAAW,EAAED,OAAO,EAAEO,UAAU,GAAG,CAAC,CAAC;MACzE;MACA,MAAM,IAAI0C,KAAK,CAAC,gCAAgC,CAAC;IACnD;IAEA,IAAI,CAACf,QAAQ,CAACgB,EAAE,EAAE;MAAA,IAAAC,gBAAA;MAChB,MAAMC,SAAS,GAAG,MAAMlB,QAAQ,CAACmB,IAAI,CAAC,CAAC,CAACC,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;MACzD,MAAM,IAAIL,KAAK,CAAC,EAAAE,gBAAA,GAAAC,SAAS,CAACG,KAAK,cAAAJ,gBAAA,uBAAfA,gBAAA,CAAiBK,OAAO,KAAI,QAAQtB,QAAQ,CAACU,MAAM,EAAE,CAAC;IACxE;IAEA,MAAMa,IAAI,GAAG,MAAMvB,QAAQ,CAACmB,IAAI,CAAC,CAAC;IAElC,IAAI,GAAApB,gBAAA,GAACwB,IAAI,CAACC,UAAU,cAAAzB,gBAAA,eAAfA,gBAAA,CAAkB,CAAC,CAAC,GAAE;MACzB,MAAM,IAAIgB,KAAK,CAAC,gBAAgB,CAAC;IACnC;IAEA,IAAIN,IAAI,GAAGc,IAAI,CAACC,UAAU,CAAC,CAAC,CAAC,CAACC,OAAO,CAACjB,KAAK,CAAC,CAAC,CAAC,CAACC,IAAI;IACnD,IAAIiB,MAAM;IAEV,IAAI;MACF;MACAjB,IAAI,GAAGA,IAAI,CAACkB,OAAO,CAAC,aAAa,EAAE,EAAE,CAAC,CAACA,OAAO,CAAC,SAAS,EAAE,EAAE,CAAC;MAC7D,MAAMC,SAAS,GAAGnB,IAAI,CAACoB,KAAK,CAAC,aAAa,CAAC;MAE3CH,MAAM,GAAGE,SAAS,GAAGvB,IAAI,CAACyB,KAAK,CAACF,SAAS,CAAC,CAAC,CAAC,CAAC,GAAG;QAC9CG,SAAS,EAAEtB,IAAI,CAACvC,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC;QACjC8D,SAAS,EAAE,EAAE;QACbC,gBAAgB,EAAE,CAAC;QACnBC,iBAAiB,EAAE,CAAC;QACpBC,OAAO,EAAE,CAAC,MAAM;MAClB,CAAC;IACH,CAAC,CAAC,OAAOC,CAAC,EAAE;MACVzD,OAAO,CAAC0C,KAAK,CAAC,aAAa,EAAEe,CAAC,CAAC;MAC/BV,MAAM,GAAG;QACPK,SAAS,EAAEtB,IAAI,CAACvC,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC;QACjC8D,SAAS,EAAE,EAAE;QACbC,gBAAgB,EAAE,CAAC;QACnBC,iBAAiB,EAAE,CAAC;QACpBC,OAAO,EAAE,CAAC,MAAM;MAClB,CAAC;IACH;;IAEA;IACA,IAAIzE,KAAK,CAAC2E,IAAI,IAAIzE,cAAc,EAAE;MAChC,MAAM0E,QAAQ,GAAG5E,KAAK,CAAC6E,IAAI,CAAC,CAAC,CAACC,IAAI,CAAC,CAAC,CAACC,KAAK;MAC1C/E,KAAK,CAACgF,MAAM,CAACJ,QAAQ,CAAC;IACxB;IACA5E,KAAK,CAACiF,GAAG,CAAClE,QAAQ,EAAEiD,MAAM,CAAC;IAE3B,OAAOA,MAAM;EAEf,CAAC,CAAC,OAAOL,KAAK,EAAE;IACd1C,OAAO,CAAC0C,KAAK,CAAC,YAAY,EAAEA,KAAK,CAAC;IAClC,MAAMA,KAAK;EACb;AACF","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}